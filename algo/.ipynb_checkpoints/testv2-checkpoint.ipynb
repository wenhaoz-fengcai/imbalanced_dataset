{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from hybridboost import HybridBoost \n",
    "from smote import SMOTEBoost \n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smoteBoost(object):\n",
    "    def __init__(self, base_learner=DT(max_depth=2),\n",
    "                 n_estimators=3,\n",
    "                 smote_ratio=10,\n",
    "                 class_numsamples_dict=False,\n",
    "                 df_smote=False,\n",
    "                 smote_decay='linear'):\n",
    "        self.m = base_learner\n",
    "        self.T = n_estimators\n",
    "        self.smote_ratio = smote_ratio\n",
    "        self.class_numsamples_dict = class_numsamples_dict\n",
    "        self.df_smote = df_smote\n",
    "        self.smote_decay = smote_decay\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # initialize list to hold models and model weights (alphas)\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "\n",
    "        xconstant = x.copy()\n",
    "        yconstant = y.copy()\n",
    "\n",
    "        # initialize weights\n",
    "        w0 = 1.0 / x.shape[0]\n",
    "        w = pd.Series([w0]*x.shape[0], index=x.index)\n",
    "        w.name = 'w'\n",
    "        w_index = w.index.values\n",
    "\n",
    "        # iterate T times\n",
    "        for i in range(self.T):\n",
    "            # modify the distribution by creating N synthetic examples from minority class\n",
    "            synthetic_indices = []\n",
    "            for c in self.class_numsamples_dict:\n",
    "                df_c = self.df_smote[self.df_smote.cl == c]\n",
    "                synthetic_ind = random.sample(df_c.index, \\\n",
    "                    np.minimum(int(self.class_numsamples_dict[c]*self.smote_ratio), df_c.shape[0]))\n",
    "                for i in synthetic_ind:\n",
    "                    synthetic_indices.append(i)\n",
    "            synthetic_df_round = self.df_smote.loc[synthetic_indices]\n",
    "            xsynthetic = synthetic_df_round.drop(['cl','filepath'], axis=1)\n",
    "            ysynthetic = synthetic_df_round.cl\n",
    "            xsmote = pd.concat([x, xsynthetic])\n",
    "            ysmote = pd.concat([y, ysynthetic])\n",
    "\n",
    "            # train a weak learner\n",
    "            clf = self.m.fit(xsmote, ysmote)\n",
    "            self.models.append(clf)\n",
    "\n",
    "            # make predictions and compute loss\n",
    "            predtrain = clf.predict(xconstant)\n",
    "            df_err = pd.DataFrame({'pred':predtrain, 'actual':y})\n",
    "            h_t = (df_err['pred'] != df_err['actual'])*1\n",
    "            e = 0.5*h_t.values.dot(w.values).sum()\n",
    "\n",
    "            # update alpha\n",
    "            alpha = np.log((1-e)/e)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "            # update weights\n",
    "            h = h_t.replace(0, -1).values\n",
    "            w = w.values*(np.exp(-alpha*h))\n",
    "            w = w / w.sum()\n",
    "            w = pd.Series(w, index=w_index)         \n",
    "\n",
    "            # update the data frame\n",
    "            new_indices = np.random.choice(w.index,\n",
    "                                           size=xconstant.shape[0],\n",
    "                                           replace=True,\n",
    "                                           p=w.values)\n",
    "            x = xconstant.loc[new_indices]\n",
    "            y = yconstant.loc[new_indices]  \n",
    "\n",
    "    def predict(self, x):\n",
    "        # iterate through each model and stuff predictions in predictions_df\n",
    "        predictions = []\n",
    "        for m in self.models:\n",
    "            # create a prediction\n",
    "            pred = m.predict(x)\n",
    "            predictions.append(pred)\n",
    "        predictions = pd.DataFrame(predictions).transpose()\n",
    "\n",
    "        # predict the class with the largest sum of alphas\n",
    "        weighted_predictions = []\n",
    "        for index, value in predictions.iterrows():\n",
    "            predictions_prob_dict = {}\n",
    "            for i in range(len(self.alphas)):\n",
    "                v = value.iloc[i]\n",
    "                if v not in predictions_prob_dict.keys():\n",
    "                    predictions_prob_dict[v] = self.alphas[i]\n",
    "                else:\n",
    "                    predictions_prob_dict[v] += self.alphas[i]\n",
    "            weighted_predictions.append(max(predictions_prob_dict, key=predictions_prob_dict.get))\n",
    "\n",
    "        return weighted_predictions\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        predictions = []\n",
    "        for m in self.models:\n",
    "            pred_proba = m.predict_proba(x)\n",
    "            predictions.append(pred_proba)\n",
    "        weighted_predictions = []\n",
    "        for i in range(len(predictions)):\n",
    "            weighted_predictions.append(self.alphas[i]*predictions[i])\n",
    "        predict_proba = sum(weighted_predictions)\n",
    "        return predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pregnant</th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_fold_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pregnant  plasma_glucose  blood_pressure  skin_fold_thickness  \\\n",
       "0             6             148              72                   35   \n",
       "1             1              85              66                   29   \n",
       "2             8             183              64                    0   \n",
       "3             1              89              66                   23   \n",
       "4             0             137              40                   35   \n",
       "\n",
       "   serum_insulin   bmi  diabetes_pedigree  age  class  \n",
       "0              0  33.6              0.627   50      1  \n",
       "1              0  26.6              0.351   31      0  \n",
       "2              0  23.3              0.672   32      1  \n",
       "3             94  28.1              0.167   21      0  \n",
       "4            168  43.1              2.288   33      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pima-indians-diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outcomes distribution\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = HybridBoost(random_state=0, n_samples=232)\n",
    "X, y= df.iloc[:,:-1].values, df[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148,  57],\n",
       "       [ 23,  80]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7493251243192044"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79       205\n",
      "           1       0.58      0.78      0.67       103\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       308\n",
      "   macro avg       0.72      0.75      0.73       308\n",
      "weighted avg       0.77      0.74      0.75       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = smoteBoost()\n",
    "X, y= df.iloc[:,:-1].values, df[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4b60392a9cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b413f4d403b6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# modify the distribution by creating N synthetic examples from minority class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0msynthetic_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_numsamples_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mdf_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_smote\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_smote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0msynthetic_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_numsamples_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmote_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758228747336017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.44      0.59       205\n",
      "           1       0.45      0.91      0.60       103\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       308\n",
      "   macro avg       0.68      0.68      0.60       308\n",
      "weighted avg       0.76      0.60      0.60       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SMOTE' object has no attribute 'fit_resample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6ed2521fbc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SMOTE' object has no attribute 'fit_resample'"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import sklearn; print(\"imblearn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
